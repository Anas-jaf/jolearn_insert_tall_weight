{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "\n",
    "# note for weight value should be 10-120\n",
    "# checkValueValidation(10, 120, this)\n",
    "\n",
    "# note for tall value should be 10-120\n",
    "# checkValueValidation(100, 200, this)\n",
    "\n",
    "def get_important_information_to_fill_weight_tall():\n",
    "    pass\n",
    "\n",
    "def scrape_FitnessWeightHeightMesaures_page(cookies):\n",
    "    response = requests.get(\n",
    "        'https://jolearn.jo/index.php?r=EFitness/FitnessWeightHeightMesaures/create',\n",
    "        cookies=cookies,\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "def get_grades_data(html_text):\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "    # Find the select dropdown by ID\n",
    "    select_dropdown = soup.find('select', {'id': 'FitnessSchoolSort_ViewCodeNameWHMeasures_GradeID'})\n",
    "\n",
    "    # Check if the select dropdown is found\n",
    "    if select_dropdown:\n",
    "        # Extract options\n",
    "        grades = []\n",
    "        for option in select_dropdown.find_all('option'):\n",
    "            value = option.get('value')\n",
    "            text = option.get_text(strip=True)\n",
    "            if \"ختر\" not in text :\n",
    "                grades.append({'value': value, 'text': text})\n",
    "        # print(grades)\n",
    "        return grades\n",
    "    \n",
    "def get_schools_data(html_text):\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "    # Find the select dropdown by ID\n",
    "    select_dropdown = soup.find('select', {'id': 'SchoolID'})\n",
    "\n",
    "    # Check if the select dropdown is found\n",
    "    if select_dropdown:\n",
    "        # Extract options\n",
    "        schools = []\n",
    "        for option in select_dropdown.find_all('option'):\n",
    "            value = option.get('value')\n",
    "            text = option.get_text(strip=True)\n",
    "            if len(value):\n",
    "                schools.append({'value': value, 'text': text})\n",
    "        # print(schools)\n",
    "        return schools\n",
    "    \n",
    "def scrape_students_FitnessWeightHeightMesaures_html(cookies , schoolId , gradeId):\n",
    "    data = {\n",
    "    'viewCodeName': 'ViewCodeNameWHMeasures',\n",
    "    'SchoolID': schoolId,\n",
    "    'GradeID': gradeId,\n",
    "    # 'SchoolID': '4B9EEE39-FC46-4AA7-A33D-1F3FE5E99AC1',\n",
    "    # 'GradeID': '6363D458-760B-4E5C-8C1D-E15DDA9C13A1',\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        'https://jolearn.jo/index.php?r=EFitness/FitnessWeightHeightMesaures/GetListOfAllStudentsPeriods',\n",
    "        cookies=cookies,\n",
    "        data=data,\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "def get_students_FitnessWeightHeightMesaures_data(html_text):\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "    # Find all rows with class 'weightHeightMesauresRow'\n",
    "    rows = soup.find_all('tr', class_='weightHeightMesauresRow')\n",
    "\n",
    "    # Extract names and corresponding MesaureStudentID values and store in a list of dictionaries\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        name = row.find('td').get_text(strip=True)\n",
    "        mesaure_student_id = row.find('input', {'name': 'MesaureStudentID'})['value']\n",
    "        test_period_id = row.find('input', {'name': 'testPeriodID'})['value']\n",
    "        data.append({'name': name, 'mesaure_student_id': mesaure_student_id, 'test_period_id': test_period_id})\n",
    "\n",
    "    return data\n",
    "\n",
    "def random_request_payload_FitnessWeightHeightMesaures(students_data,w_range=(85, 100) , h_range=(100, 120) ):\n",
    "    # Define the weight and height ranges\n",
    "    weight_range = w_range\n",
    "    height_range = h_range\n",
    "\n",
    "    # Generate the dictionary\n",
    "    fitness_data = []\n",
    "    for item in students_data:\n",
    "        entry = {\n",
    "            \"StudentID\": item['mesaure_student_id'],\n",
    "            \"Weight\": str(random.randint(*weight_range)),\n",
    "            \"Height\": str(random.randint(*height_range)),\n",
    "            \"TestPeriod\": item['test_period_id']\n",
    "        }\n",
    "        fitness_data.append(entry)\n",
    "\n",
    "    # Convert the list of dictionaries to a JSON-like string\n",
    "    fitness_data_str = {'FitnessWeightHeightMesaures':str(fitness_data).replace(\"'\", '\"')}\n",
    "    return fitness_data_str\n",
    "\n",
    "# suggestions to make the code better :\n",
    "# 1. scrape all students data at once then posting them all together\n",
    "# 2. login to microsoft and get the cookies with requests library instead of selenium library\n",
    "\n",
    "# cookies = {\n",
    "#     'PHPSESSID': 'r86mi4ope2snec78rb8h7emk6d',\n",
    "#     'ARRAffinity': 'afb7226a31ec5e26360c36e5e18645c7826aa5dd89a26f31b33c5ca2e1c5d7bd',\n",
    "#     'ARRAffinitySameSite': 'afb7226a31ec5e26360c36e5e18645c7826aa5dd89a26f31b33c5ca2e1c5d7bd'\n",
    "# }\n",
    "\n",
    "# FitnessWeightHeightMesaures_page = scrape_FitnessWeightHeightMesaures_page(cookies)\n",
    "# schools = [ i['value'] for i in get_schools_data(FitnessWeightHeightMesaures_page)][0]\n",
    "# grades = get_grades_data(FitnessWeightHeightMesaures_page)\n",
    "\n",
    "# for grade in grades:\n",
    "#     html_text = scrape_students_FitnessWeightHeightMesaures_html(cookies , schools , grade['value'])\n",
    "#     students_data = [i for i in get_students_FitnessWeightHeightMesaures_data(html_text)]\n",
    "#     request_payload = random_request_payload_FitnessWeightHeightMesaures(students_data)\n",
    "    \n",
    "#     response = requests.post(\n",
    "#         'https://jolearn.jo/index.php?r=EFitness/FitnessWeightHeightMesaures/create',\n",
    "#         cookies=cookies,\n",
    "#         data=request_payload\n",
    "#     )\n",
    "#     print(\" تم تعبئة الصف بنجاح \" + grade['text'])\n",
    "#     print(response.status_code )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlled_ranodmness = {'سابع' : [(140,150) ,(48,55)] ,\n",
    "                        'ثامن' : [(148,156) ,(55,62)] ,\n",
    "                        'تاسع' : [(152,160) ,(60,69)] ,\n",
    "                        'عاشر' : [(157,164) ,(64,71)] ,\n",
    "                        'حادي عشر' : [(163,170) ,(64,75)] ,\n",
    "                        'ثاني عشر' : [(163,175) ,(65,78)]}\n",
    "\n",
    "for grade in grades:\n",
    "    for item in controlled_ranodmness:\n",
    "        if item in grade['text']:\n",
    "            h_range , w_range = controlled_ranodmness[item]\n",
    "            request_payload = random_request_payload_FitnessWeightHeightMesaures(students_data ,h_range=h_range,w_range=w_range)\n",
    "            print(grade)\n",
    "        else:\n",
    "            print('not found')\n",
    "    # grade['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': '6363D458-760B-4E5C-8C1D-E15DDA9C13A1', 'text': 'الصف السابع'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uploaded  410/410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " تم تعبئة الصف بنجاح الصف السابع\n",
      "{'value': '78E1D9DB-5E83-4461-BDD7-BDD0733B1C5C', 'text': 'الصف الثامن'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uploaded  490/490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " تم تعبئة الصف بنجاح الصف الثامن\n",
      "{'value': '42B27C7A-37D1-41AD-B8E3-4E1C999EC14A', 'text': 'الصف التاسع'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uploaded  495/495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " تم تعبئة الصف بنجاح الصف التاسع\n",
      "{'value': '9A6D6429-39C2-458E-89CB-4ED9960DF4B9', 'text': 'الصف العاشر'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uploaded  450/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " تم تعبئة الصف بنجاح الصف العاشر\n",
      "{'value': 'E92F824F-C029-40CA-B225-58AEAE3684E4', 'text': 'الصف الحادي عشر الأدبي'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uploaded  385/385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " تم تعبئة الصف بنجاح الصف الحادي عشر الأدبي\n",
      "{'value': '0D97EBB9-0C4C-4D5B-9E47-AD638C73BA74', 'text': 'الصف الحادي عشر العلمي'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uploaded  105/105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " تم تعبئة الصف بنجاح الصف الحادي عشر العلمي\n",
      "{'value': '534CCEEE-9BB4-4C13-BB63-D04FDAC930C7', 'text': 'الصف الثاني عشر الأدبي'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uploaded  285/285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " تم تعبئة الصف بنجاح الصف الثاني عشر الأدبي\n",
      "{'value': '4DF525CD-7420-4D81-AFC9-3D1784B8D8E4', 'text': 'الصف الثاني عشر العلمي'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uploaded  70/70"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " تم تعبئة الصف بنجاح الصف الثاني عشر العلمي\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import wfuzz\n",
    "from urllib.parse import unquote , quote\n",
    "\n",
    "def custom_encode(s):\n",
    "    # Encode only square brackets\n",
    "    s = s.replace('[', '%5B').replace(']', '%5D')\n",
    "    return s\n",
    "\n",
    "def random_request_payload_previousFitnessScore(students_data , school_id ,previousFitnessScore_data , value_ranges=[]):\n",
    "    # Generate the dictionary\n",
    "    fitness_data = []\n",
    "    \n",
    "    trunkFlexion = previousFitnessScore_data['trunkFlexion_test_data']\n",
    "    speedAgility = previousFitnessScore_data['speedAgility_test_data']\n",
    "    flexibility = previousFitnessScore_data['flexibility_test_data']\n",
    "    running1600m = previousFitnessScore_data['running1600m_test_data']\n",
    "    inclinedArmFlexion = previousFitnessScore_data['inclinedArmFlexion_test_data']\n",
    "    \n",
    "    \n",
    "    for item in students_data:\n",
    "        student_id = item['mesaure_student_id']\n",
    "        \n",
    "        random_second = random.randint(0, 60)\n",
    "        random_milliseconds = random.randint(0, 99)\n",
    "        \n",
    "        random_value_0 = random.randint(value_ranges[0][0], value_ranges[0][1])\n",
    "        random_value_1 = f'{random.randint(value_ranges[1][0], value_ranges[1][1])}.{random_milliseconds}'\n",
    "        random_value_2 = random.randint(value_ranges[2][0], value_ranges[2][1])\n",
    "        random_value_3 = f'{random.randint(value_ranges[3][0], value_ranges[3][1])}.{random_second}'\n",
    "        random_value_4 = random.randint(value_ranges[4][0], value_ranges[4][1])\n",
    "        \n",
    "        trunkFlexion_entry = f\"FitnessScore[Age]=16&FitnessScore[Gender]=1&FitnessScore[StudentId]={student_id}&FitnessScore[SchoolId]={school_id}&FitnessScore[TestMaster]={trunkFlexion['Test_master']}&FitnessScore[TestType]={trunkFlexion['Test_type']}&FitnessScore[TestTypeId]={trunkFlexion['id']}&FitnessScore[Criteria]={random_value_0}\"\n",
    "        speedAgility_entry = f\"FitnessScore[Age]=16&FitnessScore[Gender]=1&FitnessScore[StudentId]={student_id}&FitnessScore[SchoolId]={school_id}&FitnessScore[TestMaster]={speedAgility['Test_master']}&FitnessScore[TestType]={speedAgility['Test_type']}&FitnessScore[TestTypeId]={speedAgility['id']}&FitnessScore[Criteria]={random_value_1}\"\n",
    "        flexibility_entry = f\"FitnessScore[Age]=16&FitnessScore[Gender]=1&FitnessScore[StudentId]={student_id}&FitnessScore[SchoolId]={school_id}&FitnessScore[TestMaster]={flexibility['Test_master']}&FitnessScore[TestType]={flexibility['Test_type']}&FitnessScore[TestTypeId]={flexibility['id']}&FitnessScore[Criteria]={random_value_2}\"\n",
    "        running1600m_entry = f\"FitnessScore[Age]=16&FitnessScore[Gender]=1&FitnessScore[StudentId]={student_id}&FitnessScore[SchoolId]={school_id}&FitnessScore[TestMaster]={running1600m['Test_master']}&FitnessScore[TestType]={running1600m['Test_type']}&FitnessScore[TestTypeId]={running1600m['id']}&FitnessScore[Criteria]={random_value_3}\"\n",
    "        inclinedArmFlexion_entry = f\"FitnessScore[Age]=16&FitnessScore[Gender]=1&FitnessScore[StudentId]={student_id}&FitnessScore[SchoolId]={school_id}&FitnessScore[TestMaster]={inclinedArmFlexion['Test_master']}&FitnessScore[TestType]={inclinedArmFlexion['Test_type']}&FitnessScore[TestTypeId]={inclinedArmFlexion['id']}&FitnessScore[Criteria]={random_value_4}\"\n",
    "\n",
    "        fitness_data.extend([custom_encode(trunkFlexion_entry ), custom_encode(speedAgility_entry) , custom_encode(flexibility_entry) , custom_encode(running1600m_entry) , custom_encode(inclinedArmFlexion_entry) ])\n",
    "\n",
    "    return fitness_data\n",
    "\n",
    "def enocode_string(string):\n",
    "    # encode the string\n",
    "    encoded_string = quote(string)\n",
    "    return encoded_string\n",
    "\n",
    "def scrape_previousFitnessScore_data(html):\n",
    "\n",
    "    # ثتي_الجذع_من_الرقود: trunkFlexion\n",
    "    # السرعة_والرشاقة: speedAgility\n",
    "    # مرونة: flexibility\n",
    "    # 1600م_جري: running1600m\n",
    "    # ثتي_الذراعين_من_الانبطاح_المائل: inclinedArmFlexion\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Find the first <tr> element with class \"fitnessScoreRow\"\n",
    "    first_fitness_row = soup.find('tr', class_='fitnessScoreRow')\n",
    "\n",
    "    td_elements = first_fitness_row.find_all('td')\n",
    "\n",
    "    inputs = td_elements[5:10]\n",
    "\n",
    "    trunkFlexion_test_data = {'Test_master' : inputs[0].find('input')['data--test-master'] , 'Test_type':inputs[0].find('input')['data--test-type'] , 'id':inputs[0].find('input')['data--test-type-id']}\n",
    "    speedAgility_test_data = {'Test_master' : inputs[1].find('input')['data--test-master'] , 'Test_type':inputs[1].find('input')['data--test-type'] , 'id':inputs[1].find('input')['data--test-type-id']}\n",
    "    flexibility_test_data = {'Test_master' : inputs[2].find('input')['data--test-master'] , 'Test_type':inputs[2].find('input')['data--test-type'] , 'id':inputs[2].find('input')['data--test-type-id']}\n",
    "    running1600m_test_data = {'Test_master' : inputs[3].find('input')['data--test-master'] , 'Test_type':inputs[3].find('input')['data--test-type'] , 'id':inputs[3].find('input')['data--test-type-id']}\n",
    "    inclinedArmFlexion_test_data = {'Test_master' : inputs[4].find('input')['data--test-master'] , 'Test_type':inputs[4].find('input')['data--test-type'] , 'id':inputs[4].find('input')['data--test-type-id']}\n",
    "\n",
    "    return {\n",
    "            'trunkFlexion_test_data':trunkFlexion_test_data,\n",
    "            'speedAgility_test_data':speedAgility_test_data,\n",
    "            'flexibility_test_data':flexibility_test_data,\n",
    "            'running1600m_test_data':running1600m_test_data,\n",
    "            'inclinedArmFlexion_test_data':inclinedArmFlexion_test_data,\n",
    "            }\n",
    "\n",
    "def scrape_previousFitnessScore_page (cookies , schoolId , gradeId):\n",
    "\n",
    "    data = {\n",
    "        'viewCodeName': 'PreviousFitnessScore',\n",
    "        'SchoolID': schoolId,\n",
    "        'GradeID': gradeId,\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        'https://jolearn.jo/index.php?r=EFitness/PreviousFitnessScore/GetListOfAllStudentsPeriod',\n",
    "        cookies=cookies,\n",
    "        data=data,\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "def wfuzz_function(url, fuzz_list,cookies,body_postdata,method='POST',proxies = None):\n",
    "    \"\"\"دالة استخدمها لارسال طلب بوست بشكل سريع\n",
    "\n",
    "    Args:\n",
    "        fuzz_list (list): قائمة في بيانات الطلاب المراد ادخالها\n",
    "        headers (tuple-list): راسيات الطلب او الركويست\n",
    "        body_postdata (str): جسم البوست داتا\n",
    "        method (str, optional): طريقة الطلب. Defaults to 'POST'.\n",
    "\n",
    "    Returns:\n",
    "        any : تعود بقائمة الطلبات غير الناجحة\n",
    "    \"\"\"    \n",
    "    unsuccessful_requests=[]\n",
    "    with tqdm(total=len(fuzz_list), bar_format='{postfix[0]} {n_fmt}/{total_fmt}',\n",
    "            postfix=[\"uploaded \", {\"value\": 0}]) as t:\n",
    "            s = wfuzz.get_payloads([fuzz_list])\n",
    "            for idx , r in enumerate(s.fuzz(\n",
    "                            url=url ,\n",
    "                            # hc=[404] , \n",
    "                            # payloads=[(\"list\",fuzz_list)] ,\n",
    "                            cookie=cookies ,\n",
    "                            postdata = body_postdata ,\n",
    "                            proxies= proxies ,\n",
    "                            method= method\n",
    "                            ),start =1):\n",
    "                    \n",
    "                t.postfix[1][\"value\"] = idx\n",
    "                t.update()    \n",
    "            #     print(r)\n",
    "            #     print(r.content)\n",
    "            #     print(r.history.code) # كود الركويست\n",
    "                if r.history.code != 200 :\n",
    "                    unsuccessful_requests.append(r.description)\n",
    "    return unsuccessful_requests\n",
    "\n",
    "cookies = {\n",
    "    'PHPSESSID' : '62p6dnpuvrpusigntniv21nrmd', \n",
    "    'ARRAffinity' : 'afb7226a31ec5e26360c36e5e18645c7826aa5dd89a26f31b33c5ca2e1c5d7bd', \n",
    "    'ARRAffinitySameSite' : 'afb7226a31ec5e26360c36e5e18645c7826aa5dd89a26f31b33c5ca2e1c5d7d'\n",
    "}\n",
    "\n",
    "previousFitnessScore_data = ''\n",
    "FitnessWeightHeightMesaures_page = scrape_FitnessWeightHeightMesaures_page(cookies)\n",
    "schools = [ i['value'] for i in get_schools_data(FitnessWeightHeightMesaures_page)][0]\n",
    "grades = get_grades_data(FitnessWeightHeightMesaures_page)\n",
    "url = 'https://jolearn.jo/index.php?r=EFitness/PreviousFitnessScore/create'\n",
    "\n",
    "proxies = [('127.0.0.1','8080','HTTP')]\n",
    "\n",
    "controlled_ranodmness_previous_fitness_score = {'سابع' : [(20,27) ,(10,11),(24,29),(7,8),(17,26)] ,\n",
    "                        'ثامن' : [(20,29) ,(10,11),(25,28),(6,7),(19,25)] ,\n",
    "                        'تاسع' : [(25,30) ,(10,11),(27,31),(6,7),(25,27)] ,\n",
    "                        'عاشر' : [(27,35) ,(10,10),(28,32),(6,7),(24,29)] ,\n",
    "                        'حادي عشر' : [(30,36) ,(10,11),(30,35),(6,7),(25,32)] ,\n",
    "                        'ثاني عشر' : [(34,40) ,(10,11),(32,36),(6,7),(27,35)]}\n",
    "\n",
    "\n",
    "for grade in grades:\n",
    "    html_text = scrape_students_FitnessWeightHeightMesaures_html(cookies , schools , grade['value'])\n",
    "    if not len(previousFitnessScore_data) :\n",
    "        response = scrape_previousFitnessScore_page(cookies , schools ,grade['value'])\n",
    "        previousFitnessScore_data = scrape_previousFitnessScore_data(response)\n",
    "        \n",
    "    students_data = [i for i in get_students_FitnessWeightHeightMesaures_data(html_text)]\n",
    "    # request_payload = random_request_payload_previousFitnessScore(students_data , previousFitnessScore_data)\n",
    "    \n",
    "    for item in controlled_ranodmness_previous_fitness_score:\n",
    "        if item in grade['text']:\n",
    "            value_ranges = controlled_ranodmness_previous_fitness_score[item]\n",
    "            request_payload = random_request_payload_previousFitnessScore(students_data , schools , previousFitnessScore_data , value_ranges)\n",
    "            # [f'{i[0]}={i[1]}' for i in cookies.items()]\n",
    "            print(grade)\n",
    "        # else:\n",
    "        #     print('not found')\n",
    "\n",
    "\n",
    "    wfuzz_cookie = [f\"{i[0]}={i[1]}\" for i in cookies.items()]\n",
    "    \n",
    "    unsuccessful_requests = wfuzz_function(url , request_payload , wfuzz_cookie ,'FUZZ' ,method='POST',proxies = proxies)\n",
    "\n",
    "    while len(unsuccessful_requests) != 0:\n",
    "        unsuccessful_requests = wfuzz_function(url , unsuccessful_requests , wfuzz_cookie ,'FUZZ' ,method='POST',proxies = proxies)\n",
    "\n",
    "    print(\" تم تعبئة الصف بنجاح \" + grade['text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selenium_stuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
